{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c145a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:28.833547Z",
     "iopub.status.busy": "2023-04-02T11:39:28.833106Z",
     "iopub.status.idle": "2023-04-02T11:39:39.213378Z",
     "shell.execute_reply": "2023-04-02T11:39:39.211521Z"
    },
    "papermill": {
     "duration": 10.391441,
     "end_time": "2023-04-02T11:39:39.217489",
     "exception": false,
     "start_time": "2023-04-02T11:39:28.826048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\r\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: einops\r\n",
      "Successfully installed einops-0.6.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14861835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:39.234162Z",
     "iopub.status.busy": "2023-04-02T11:39:39.233777Z",
     "iopub.status.idle": "2023-04-02T11:39:45.699594Z",
     "shell.execute_reply": "2023-04-02T11:39:45.698460Z"
    },
    "papermill": {
     "duration": 6.476756,
     "end_time": "2023-04-02T11:39:45.702249",
     "exception": false,
     "start_time": "2023-04-02T11:39:39.225493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from einops import rearrange, repeat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd961f",
   "metadata": {
    "papermill": {
     "duration": 0.004368,
     "end_time": "2023-04-02T11:39:45.711724",
     "exception": false,
     "start_time": "2023-04-02T11:39:45.707356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Parallel distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6b1727",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:45.723330Z",
     "iopub.status.busy": "2023-04-02T11:39:45.722053Z",
     "iopub.status.idle": "2023-04-02T11:39:49.317381Z",
     "shell.execute_reply": "2023-04-02T11:39:49.315463Z"
    },
    "papermill": {
     "duration": 3.603947,
     "end_time": "2023-04-02T11:39:49.320400",
     "exception": false,
     "start_time": "2023-04-02T11:39:45.716453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720046f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.332151Z",
     "iopub.status.busy": "2023-04-02T11:39:49.331490Z",
     "iopub.status.idle": "2023-04-02T11:39:49.336803Z",
     "shell.execute_reply": "2023-04-02T11:39:49.335504Z"
    },
    "papermill": {
     "duration": 0.013899,
     "end_time": "2023-04-02T11:39:49.339472",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.325573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "DATA_LENGTH = 94477\n",
    "GLOBAL_BATCH_SIZE = 32\n",
    "BATCH_SIZE_PER_REPLICA = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809c97d",
   "metadata": {
    "papermill": {
     "duration": 0.004803,
     "end_time": "2023-04-02T11:39:49.348978",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.344175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a363e53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.360271Z",
     "iopub.status.busy": "2023-04-02T11:39:49.359555Z",
     "iopub.status.idle": "2023-04-02T11:39:49.477632Z",
     "shell.execute_reply": "2023-04-02T11:39:49.476641Z"
    },
    "papermill": {
     "duration": 0.126111,
     "end_time": "2023-04-02T11:39:49.480023",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.353912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Read TFRecord file\n",
    "def _parse_tfr_element(element):\n",
    "    parse_dic = {\n",
    "    'b_feature': tf.io.FixedLenFeature([], tf.string), # Note that it is tf.string, not tf.float32\n",
    "    'b_label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example_message = tf.io.parse_single_example(element, parse_dic)\n",
    "\n",
    "    b_feature = example_message['b_feature'] # get byte string\n",
    "    b_label = example_message['b_label']\n",
    "    \n",
    "    feature = tf.io.parse_tensor(b_feature, out_type=tf.float32) # restore 2D array from byte string\n",
    "    label = tf.io.parse_tensor(b_label, out_type=tf.int32)\n",
    "    return (feature, label)\n",
    "\n",
    "filenames = [f'/kaggle/input/tfrecords-sequences-for-asl/data{i}.tfrecords' for i in range(20)]\n",
    "dataset = tf.data.TFRecordDataset(filenames) \n",
    "dataset = dataset.map(_parse_tfr_element, num_parallel_calls=AUTO).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412f9d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.490897Z",
     "iopub.status.busy": "2023-04-02T11:39:49.490609Z",
     "iopub.status.idle": "2023-04-02T11:39:49.532887Z",
     "shell.execute_reply": "2023-04-02T11:39:49.531922Z"
    },
    "papermill": {
     "duration": 0.050425,
     "end_time": "2023-04-02T11:39:49.535194",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.484769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_shapes(feature, label):\n",
    "    feature.set_shape((50, 115, 3))\n",
    "    label.set_shape([])\n",
    "    return feature, label\n",
    "\n",
    "dataset = dataset.map(set_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9b962",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.004512,
     "end_time": "2023-04-02T11:39:49.544652",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.540140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "def load_data_out():\n",
    "    feature = []\n",
    "    label = []\n",
    "    for i,j in enumerate(dataset):\n",
    "        feature.append(j[0])\n",
    "        label.append(j[1])\n",
    "    return tf.stack(feature,0), tf.stack(label,0)\n",
    "\n",
    "X,y = load_data_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb2e45",
   "metadata": {
    "papermill": {
     "duration": 0.004704,
     "end_time": "2023-04-02T11:39:49.554258",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.549554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Model + Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a8bc44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.565269Z",
     "iopub.status.busy": "2023-04-02T11:39:49.564897Z",
     "iopub.status.idle": "2023-04-02T11:39:49.573379Z",
     "shell.execute_reply": "2023-04-02T11:39:49.572323Z"
    },
    "papermill": {
     "duration": 0.01619,
     "end_time": "2023-04-02T11:39:49.575391",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.559201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2010.11929v2.pdf flattened 2D patch\n",
    "def patching(input_tensor,pad_dim):\n",
    "    #assert input_tensor.shape == (50,115,3), \"input tensor must be of shape (50,115,3)\"\n",
    "    assert 50 % pad_dim == 0, \"padding should be divisible by 50\"\n",
    "    return tf.reshape(input_tensor,shape=(input_tensor.shape[0],int((input_tensor.shape[1]*input_tensor.shape[2])//(pad_dim*input_tensor.shape[2])),int(pad_dim*input_tensor.shape[2]*input_tensor.shape[3])))\n",
    "\n",
    "def positional_embedding(d_model,length):\n",
    "    lines = np.arange(1,length+1,1)[:,np.newaxis] # (1,length)\n",
    "    temp = np.arange(1,(d_model+1)/2,1)           \n",
    "    # 1,2,3,4 becomes 1,1,2,2,3,3,4,4\n",
    "    columns = np.asarray([value for twin in zip(temp,temp) for value in twin])[np.newaxis,:] # (depth,1)\n",
    "    # apply to the previous vector the \"famous\" omega minuscule\n",
    "    columns = 1/np.power(10000,2*columns/d_model)\n",
    "    # create the matrix and apply sin, cos to pair and odd element of the vector\n",
    "    matrice = lines*columns                                                          # (depth,length)\n",
    "    matrice[:,0::2] = np.sin(matrice[:,0::2])\n",
    "    matrice[:,1::2] = np.cos(matrice[:,1::2])\n",
    "    return matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53a9799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.586796Z",
     "iopub.status.busy": "2023-04-02T11:39:49.586498Z",
     "iopub.status.idle": "2023-04-02T11:39:49.601256Z",
     "shell.execute_reply": "2023-04-02T11:39:49.600356Z"
    },
    "papermill": {
     "duration": 0.023024,
     "end_time": "2023-04-02T11:39:49.603358",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.580334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LPFP(tf.keras.layers.Layer):\n",
    "    def __init__(self, pad_dim, d_model):\n",
    "        super(LPFP,self).__init__()\n",
    "        self.pad_dim = pad_dim\n",
    "        self.d_model = d_model\n",
    "        self.dense = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "\n",
    "    def call(self,sample):\n",
    "        patched_input = patching(sample,self.pad_dim)\n",
    "        #print(patched_input.shape,'patched input')\n",
    "        output = self.dense(patched_input)\n",
    "        #print(patched_input.shape,'patched input dense')\n",
    "        return output\n",
    "\n",
    "class CLSTokenHandler(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model):\n",
    "        super(CLSTokenHandler,self).__init__()\n",
    "        self.text_vectorizer = tf.keras.layers.TextVectorization()\n",
    "        self.embedding = tf.keras.layers.Embedding(2,d_model)\n",
    "    \n",
    "    def call(self,tokenvalue):\n",
    "        self.text_vectorizer.set_vocabulary(vocabulary=[tokenvalue])\n",
    "        text_vector = self.text_vectorizer(tokenvalue)\n",
    "        embedding = self.embedding(text_vector)\n",
    "        return embedding\n",
    "    \n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,length):\n",
    "        super(PositionalEmbedding,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.length = length\n",
    "        self.positionalencoding = positional_embedding(self.d_model,self.length)\n",
    "        \n",
    "    def call(self,matrix):\n",
    "        # add positional embedding taking care of batch dimension (expand dim and repeat)\n",
    "        # matrix.shape[0] contains the batch dimension\n",
    "        matrix += tf.cast(tf.repeat(tf.expand_dims(self.positionalencoding,0),matrix.shape[0],axis=0),\"float32\")\n",
    "        return matrix\n",
    "    \n",
    "class InitBlock(tf.keras.layers.Layer):\n",
    "    def  __init__(self,pad_dim=5,d_model=768):\n",
    "        super(InitBlock,self).__init__()\n",
    "        self.pad_dim = pad_dim\n",
    "        self.d_model = d_model\n",
    "        self.LPFP = LPFP(pad_dim,d_model)\n",
    "        self.CLSTokenHandler = CLSTokenHandler(d_model)\n",
    "        # divided by 50 since we only accept inputs of size (50,115,3) \n",
    "        # 50 being the static length of the input\n",
    "        # length of positional embeding should be of the same size as input length\n",
    "        # for example 50,115,3 patched by 5 produces an input of shape 10x768 after linear\n",
    "        # length (50//5) should also be equal to 10, hence the length of the input is the same\n",
    "        # as the positional size since they are added to each other. \n",
    "        # I'm writing all the text if you're going to update the code to work with any input size.\n",
    "        self.PositionalEmbedding = PositionalEmbedding(d_model,50//pad_dim)\n",
    "        \n",
    "    def call(self,input_):\n",
    "        #print(input_.shape,'before lpfp')\n",
    "        input_matrix = self.LPFP(input_)\n",
    "        #print(input_matrix.shape,'before posemb after lpfp')\n",
    "        input_matrix = self.PositionalEmbedding(input_matrix)\n",
    "        #print(input_matrix.shape,'after posemb')\n",
    "        token_embedding = self.CLSTokenHandler('[class]')\n",
    "        \n",
    "        \n",
    "        token_embedding = tf.repeat(tf.expand_dims(token_embedding,0),input_.shape[0],axis=0)\n",
    "        #token_embedding = tf.ensure_shape(token_embedding,shape=(32,1,768))\n",
    "        token_embedding.set_shape((None,1,self.d_model))\n",
    "        #print(token_embedding.shape,'token embedding')\n",
    "        #print(token_embedding,'token embedding')\n",
    "        z0 = tf.concat([input_matrix,token_embedding],1) \n",
    "        #print(z0.shape,'after cls added')\n",
    "        return z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f97e097f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.614122Z",
     "iopub.status.busy": "2023-04-02T11:39:49.613836Z",
     "iopub.status.idle": "2023-04-02T11:39:49.623003Z",
     "shell.execute_reply": "2023-04-02T11:39:49.622104Z"
    },
    "papermill": {
     "duration": 0.016868,
     "end_time": "2023-04-02T11:39:49.625037",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.608169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# h = n_heads\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,h=12):\n",
    "        super().__init__()\n",
    "        assert d_model%h == 0 , \"n_heads (h) must be a divisor of d_model\"\n",
    "        self.h = h\n",
    "        self.d_model = d_model\n",
    "        self.Wq = tf.keras.layers.Dense(d_model,use_bias=False)\n",
    "        self.Wk = tf.keras.layers.Dense(d_model,use_bias=False)\n",
    "        self.Wv = tf.keras.layers.Dense(d_model,use_bias=False)\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self,input_):\n",
    "\n",
    "        Q = self.Wq(input_)\n",
    "        K = self.Wk(input_)\n",
    "        V = self.Wv(input_)\n",
    "\n",
    "        Q = rearrange(Q, 'b p (d h) -> b h p d',h=self.h)\n",
    "        K = rearrange(K, 'b p (d h) -> b h p d',h=self.h)\n",
    "        V = rearrange(V, 'b p (d h) -> b h d p',h=self.h) # transposed for matmul\n",
    "        \n",
    "        matmul = tf.matmul(K,V)\n",
    "        mat_scaled = matmul/tf.cast(np.sqrt(self.d_model/self.h),'float32')\n",
    "        softm = tf.nn.softmax(mat_scaled)\n",
    "        out = tf.matmul(softm,Q)\n",
    "        \n",
    "        out = rearrange(out, 'b h p d -> b p (d h)')\n",
    "        \n",
    "        out = self.dense(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da92ebc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.635651Z",
     "iopub.status.busy": "2023-04-02T11:39:49.635349Z",
     "iopub.status.idle": "2023-04-02T11:39:49.644952Z",
     "shell.execute_reply": "2023-04-02T11:39:49.643879Z"
    },
    "papermill": {
     "duration": 0.017478,
     "end_time": "2023-04-02T11:39:49.647234",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.629756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "    def __init__(self,dense_size):\n",
    "        assert isinstance(dense_size,list) , \"layer_size must be a list\"\n",
    "        super().__init__()\n",
    "        self.dense_size = dense_size\n",
    "        self.num_layer = len(dense_size)\n",
    "        self.dense_array = []\n",
    "        for i in range(self.num_layer):\n",
    "            self.dense_array.append(tf.keras.layers.Dense(dense_size[i]))\n",
    "            \n",
    "    def call(self,input_):\n",
    "        for dense in self.dense_array:\n",
    "            input_ = dense(input_)\n",
    "        return input_\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,n_head=12, dense_size=[768], d_model=768):\n",
    "        assert isinstance(dense_size,list) , \"dense_size must be a list\"\n",
    "        super().__init__()\n",
    "        self.nhead = n_head\n",
    "        self.dense_size = dense_size\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.mha = MultiHeadAttention(d_model,n_head)\n",
    "        self.mlp = MLP(dense_size)\n",
    "    \n",
    "    def call(self,input_):\n",
    "        batch_n = self.batchnorm(input_)\n",
    "        mha_out = self.mha(batch_n)\n",
    "\n",
    "        added = tf.keras.layers.Add()([input_,mha_out])\n",
    "\n",
    "        batch_n = self.batchnorm(added)\n",
    "        mlp_out = self.mlp(batch_n)\n",
    "\n",
    "        added = tf.keras.layers.Add()([added,mlp_out])\n",
    "\n",
    "        return added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ca119c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.659484Z",
     "iopub.status.busy": "2023-04-02T11:39:49.658692Z",
     "iopub.status.idle": "2023-04-02T11:39:49.667480Z",
     "shell.execute_reply": "2023-04-02T11:39:49.666520Z"
    },
    "papermill": {
     "duration": 0.017714,
     "end_time": "2023-04-02T11:39:49.669498",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.651784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Network(tf.keras.Model):\n",
    "    def __init__(self,Layers=12,pad_dim=5,n_head=12, dense_size=[768], d_model=768, output_dense_size=768):\n",
    "        super().__init__()\n",
    "        self.Layers = Layers\n",
    "        self.init_block = InitBlock(pad_dim=pad_dim,d_model=d_model)\n",
    "        self.transformer_block = TransformerBlock(n_head=n_head, dense_size=dense_size, d_model=d_model)\n",
    "        self.dense_layer1 = tf.keras.layers.Dense(output_dense_size,activation='gelu')\n",
    "        self.dense_layer2 = tf.keras.layers.Dense(250,activation='gelu')\n",
    "        self.flattener = tf.keras.layers.Flatten()\n",
    "    \n",
    "    def call(self,input_):\n",
    "        print(input_.shape,'before init block')\n",
    "        input_ = self.init_block(input_)\n",
    "        print(input_.shape,'after init block')\n",
    "        for _ in range(self.Layers):\n",
    "            input_ = self.transformer_block(input_)\n",
    "        \n",
    "        #print(input_.shape)\n",
    "        x = rearrange(input_,'b (h l) c -> b h (l c)', h=1)\n",
    "        #print(x.shape)\n",
    "        x = self.dense_layer1(x)\n",
    "        x = self.dense_layer2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af51dead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.680511Z",
     "iopub.status.busy": "2023-04-02T11:39:49.679646Z",
     "iopub.status.idle": "2023-04-02T11:39:49.691331Z",
     "shell.execute_reply": "2023-04-02T11:39:49.690437Z"
    },
    "papermill": {
     "duration": 0.019463,
     "end_time": "2023-04-02T11:39:49.693528",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.674065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = int(0.9*DATA_LENGTH)\n",
    "test_size = int(0.1*DATA_LENGTH)\n",
    "\n",
    "dataset = dataset.shuffle(DATA_LENGTH)\n",
    "train_dataset = dataset.take(train_size)\n",
    "test_dataset = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561e0f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:49.704491Z",
     "iopub.status.busy": "2023-04-02T11:39:49.704025Z",
     "iopub.status.idle": "2023-04-02T11:39:50.063032Z",
     "shell.execute_reply": "2023-04-02T11:39:50.061851Z"
    },
    "papermill": {
     "duration": 0.367467,
     "end_time": "2023-04-02T11:39:50.065861",
     "exception": false,
     "start_time": "2023-04-02T11:39:49.698394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------- Scope definition ---------------\n",
    "with strategy.scope():\n",
    "    model = Network(12,5,8,[256],256,256)\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss(labels,predictions)\n",
    "        loss_val = tf.nn.compute_average_loss(per_example_loss,global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "        return loss_val\n",
    "\n",
    "# ----------- Train and Val Step ---------------\n",
    "def train_step(inputs):\n",
    "    feature, label = inputs\n",
    "    \n",
    "    # forward and backward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(feature,training=True)\n",
    "        loss_val = compute_loss(label,logits)\n",
    "    grads = tape.gradient(loss_val, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
    "    \n",
    "    # process accuracy\n",
    "    train_accuracy.update_state(label,logits)\n",
    "        \n",
    "    return loss_val, train_accuracy\n",
    "\n",
    "def val_step(inputs):\n",
    "    feature, label = inputs\n",
    "    \n",
    "    val_logits = model(feature,training=False)\n",
    "    val_loss = loss(label,val_logits)\n",
    "    \n",
    "    test_loss.update_state(val_loss)\n",
    "    val_accuracy.update_state(label,val_logits)\n",
    "    \n",
    "    return val_accuracy,test_loss,val_loss\n",
    "\n",
    "# ----------- Distribution Wrapper ---------------\n",
    "@tf.function\n",
    "def distributed_train_step(train_ds):\n",
    "    per_replica_losses_and_acc = strategy.run(train_step,args=(train_ds,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM,per_replica_losses_and_acc[0],axis=None), per_replica_losses_and_acc[1].result()\n",
    "\n",
    "@tf.function\n",
    "def distributed_test_step(test_ds):\n",
    "    return strategy.run(test_step, args=(test_ds,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c5146d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T11:39:50.081820Z",
     "iopub.status.busy": "2023-04-02T11:39:50.081534Z"
    },
    "papermill": {
     "duration": 289.591039,
     "end_time": "2023-04-02T11:44:39.663986",
     "exception": false,
     "start_time": "2023-04-02T11:39:50.072947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 50, 115, 3) before init block\n",
      "(16, 11, 256) after init block\n",
      "(16, 50, 115, 3) before init block\n",
      "(16, 11, 256) after init block\n",
      "(16, 50, 115, 3) before init block\n",
      "(16, 11, 256) after init block\n",
      "(16, 50, 115, 3) before init block\n",
      "(16, 11, 256) after init block\n",
      "85024/85056 [============================>.] - ETA: 0s - acc: 0.0049 - loss: 5.6196(5, 50, 115, 3) before init block\n",
      "(5, 11, 256) after init block\n",
      "(0, 50, 115, 3) before init block\n",
      "(0, 11, 256) after init block\n",
      "85056/85056 [==============================] - 237s 3ms/step - acc: 0.0049 - loss: 5.6178\n"
     ]
    }
   ],
   "source": [
    "# -------------- Training ----------------\n",
    "epochs = 100\n",
    "cost_val = 0\n",
    "\n",
    "history = {}\n",
    "history['train_accuracy'] = []\n",
    "history['test_accuracy'] = []\n",
    "history['train_loss'] = []\n",
    "history['test_loss'] = []\n",
    "history['mean_loss'] = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    pb=tf.keras.utils.Progbar(target=85056)\n",
    "    \n",
    "    \n",
    "    for x in strategy.experimental_distribute_dataset(train_dataset.batch(GLOBAL_BATCH_SIZE)):\n",
    "        loss_val, acc = distributed_train_step(x)\n",
    "        cost_val += loss_val\n",
    "        \n",
    "        #history['train_accuracy'].append(acc)\n",
    "        #history['train_loss'].append(loss_val)\n",
    "        \n",
    "        pb.add(GLOBAL_BATCH_SIZE, values=[('acc',acc),('loss',loss_val)])\n",
    "        \n",
    "acc.reset_state()\n",
    "\n",
    "# Process validation data at the end of each epoch\n",
    "for x in strategy.experimental_distribute_dataset(test_dataset):\n",
    "    val_accuracy, test_loss,val_loss = distributed_test_step(x)\n",
    "    #history['test_accuracy'].append(val_accuracy.result())\n",
    "    #history['test_loss'].append(val_loss)\n",
    "    #history['mean_loss'].append(test_loss)\n",
    "val_accuracy.reset_state()\n",
    "test_loss.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9869adf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['test_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['test_loss'])\n",
    "plt.plot(history['train_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08e068",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 321.415877,
   "end_time": "2023-04-02T11:44:40.665980",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-02T11:39:19.250103",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
